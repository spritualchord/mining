import numpy as np
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
import matplotlib.pyplot as plt

# Simulate CluStream with sliding time windows
def clustream_simulation(data, window_size, num_micro_clusters):
    """
    Simulates CluStream by clustering data within sliding time windows.
    """
    clusters = []
    for i in range(0, len(data) - window_size + 1, window_size):
        window_data = data[i:i + window_size]
        kmeans = KMeans(n_clusters=num_micro_clusters, random_state=42)
        kmeans.fit(window_data)
        clusters.append(kmeans.cluster_centers_)
    return np.vstack(clusters)

# Cluster Evaluation
def evaluate_clusters(data, labels):
    silhouette = silhouette_score(data, labels)
    davies_bouldin = davies_bouldin_score(data, labels)
    calinski_harabasz = calinski_harabasz_score(data, labels)
    return silhouette, davies_bouldin, calinski_harabasz

# Load Dataset
file_path = "time.csv"  # Update with your CSV file path
data = pd.read_csv(file_path)

# Preprocessing: Select relevant columns (update column names as needed)
# Ensure that the selected columns are numeric for clustering
time_series_data = data[['TOTALDEMAND', 'RRP']]  # Replace with appropriate column names

# Handle missing values if any
time_series_data = time_series_data.dropna()

# Normalize Data
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
data_scaled = scaler.fit_transform(time_series_data)

# Parameters
window_size = 20  # Size of each time window for CluStream
num_micro_clusters = 3  # Number of micro-clusters in CluStream
kmeans_clusters = 5  # Number of clusters in K-Means

# CluStream Simulation
clustream_centers = clustream_simulation(data_scaled, window_size, num_micro_clusters)

# K-Means Clustering
kmeans = KMeans(n_clusters=kmeans_clusters, random_state=42)
kmeans.fit(data_scaled)
kmeans_labels = kmeans.labels_

# Evaluate Clustering Quality
clustream_kmeans = KMeans(n_clusters=num_micro_clusters, random_state=42)
clustream_kmeans.fit(clustream_centers)
clustream_labels = clustream_kmeans.predict(data_scaled)

kmeans_metrics = evaluate_clusters(data_scaled, kmeans_labels)
clustream_metrics = evaluate_clusters(data_scaled, clustream_labels)

# Results Comparison
print("K-Means Clustering Metrics:")
print(f"Silhouette Coefficient: {kmeans_metrics[0]:.4f}")
print(f"Davies-Bouldin Index: {kmeans_metrics[1]:.4f}")
print(f"Calinski-Harabasz Index: {kmeans_metrics[2]:.4f}")

print("\nCluStream Clustering Metrics:")
print(f"Silhouette Coefficient: {clustream_metrics[0]:.4f}")
print(f"Davies-Bouldin Index: {clustream_metrics[1]:.4f}")
print(f"Calinski-Harabasz Index: {clustream_metrics[2]:.4f}")

# Visualization
plt.figure(figsize=(12, 6))
plt.scatter(data_scaled[:, 0], data_scaled[:, 1], c=kmeans_labels, cmap='viridis', s=30, label='K-Means Clusters')
plt.scatter(clustream_centers[:, 0], clustream_centers[:, 1], c='red', label='CluStream Micro-clusters')
plt.title("CluStream vs. K-Means Clustering")
plt.xlabel("Sensor 1 (Normalized)")
plt.ylabel("Sensor 2 (Normalized)")
plt.legend()
plt.show()